{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:51:06.275129Z",
     "start_time": "2024-06-09T09:51:05.300097Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv('TrainData_A.csv')\n",
    "aggregated_load = pd.read_csv('AggregatedLoad_A.csv')\n",
    "test_data = pd.read_csv('TestData_A.csv')\n",
    "template = pd.read_csv('DisaggregatedLoad_Template.csv')\n",
    "\n",
    "# Rename columns for convenience\n",
    "train_data.columns = ['index', 'aggregated_load'] + [f'appliance_{i}' for i in range(1, 22)]\n",
    "aggregated_load.columns = ['index', 'aggregated_load']\n",
    "test_data.columns = ['index', 'aggregated_load'] + [f'appliance_{i}' for i in range(1, 22)]\n",
    "template.columns = ['index'] + [f'appliance_{i}_pred' for i in range(1, 22)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6718a761-ffc6-43f8-a5d3-4efdfaaa8943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:51:06.290564Z",
     "start_time": "2024-06-09T09:51:06.275129Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add rolling mean feature to train, test, and aggregated_load datasets\n",
    "window_size = 10\n",
    "\n",
    "train_data['agg_load_mean'] = train_data['aggregated_load'].rolling(window=window_size, min_periods=1).mean()\n",
    "test_data['agg_load_mean'] = test_data['aggregated_load'].rolling(window=window_size, min_periods=1).mean()\n",
    "aggregated_load['agg_load_mean'] = aggregated_load['aggregated_load'].rolling(window=window_size, min_periods=1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f79b5d7-e582-43f2-860f-6eaa8fc8eafa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:51:15.328685Z",
     "start_time": "2024-06-09T09:51:06.290564Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_frequency(data, window_size):\n",
    "    # Find local maxima and minima\n",
    "    peaks, _ = find_peaks(data)\n",
    "    troughs, _ = find_peaks(-data)\n",
    "    \n",
    "    # Combine and sort indices of peaks and troughs\n",
    "    extrema = np.sort(np.concatenate([peaks, troughs]))\n",
    "    \n",
    "    # Calculate frequency of extrema within the window\n",
    "    frequency = np.zeros_like(data)\n",
    "    for i in range(len(data)):\n",
    "        start = max(0, i - window_size)\n",
    "        end = i\n",
    "        frequency[i] = np.sum((extrema >= start) & (extrema < end))\n",
    "    \n",
    "    return frequency\n",
    "\n",
    "# Add frequency feature to train, test, and aggregated_load datasets\n",
    "train_data['agg_load_freq'] = calculate_frequency(train_data['aggregated_load'].values, window_size)\n",
    "test_data['agg_load_freq'] = calculate_frequency(test_data['aggregated_load'].values, window_size)\n",
    "aggregated_load['agg_load_freq'] = calculate_frequency(aggregated_load['aggregated_load'].values, window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfef7d71-3c1b-4247-bf71-8b564f239fc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:51:15.407063Z",
     "start_time": "2024-06-09T09:51:15.329684Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize the data for aggregated load, its mean, and frequency separately\n",
    "scaler_agg = StandardScaler()\n",
    "scaler_agg_mean = StandardScaler()\n",
    "scaler_agg_freq = StandardScaler()\n",
    "scaler_appliances = StandardScaler()\n",
    "\n",
    "# Fit scaler on the aggregated load, its mean, and frequency from training data\n",
    "train_agg_normalized = scaler_agg.fit_transform(train_data[['aggregated_load']])\n",
    "train_agg_mean_normalized = scaler_agg_mean.fit_transform(train_data[['agg_load_mean']])\n",
    "train_agg_freq_normalized = scaler_agg_freq.fit_transform(train_data[['agg_load_freq']])\n",
    "\n",
    "# Fit scaler on the appliance loads from training data\n",
    "train_appliances_normalized = scaler_appliances.fit_transform(train_data.iloc[:, 2:-2])  # Exclude agg_load_mean and agg_load_freq\n",
    "\n",
    "# Concatenate the normalized aggregate load, its mean, and frequency\n",
    "train_features_normalized = np.concatenate([train_agg_normalized, train_agg_mean_normalized, train_agg_freq_normalized], axis=1)\n",
    "test_features_normalized = np.concatenate([\n",
    "    scaler_agg.transform(test_data[['aggregated_load']]),\n",
    "    scaler_agg_mean.transform(test_data[['agg_load_mean']]),\n",
    "    scaler_agg_freq.transform(test_data[['agg_load_freq']])\n",
    "], axis=1)\n",
    "aggregated_features_normalized = np.concatenate([\n",
    "    scaler_agg.transform(aggregated_load[['aggregated_load']]),\n",
    "    scaler_agg_mean.transform(aggregated_load[['agg_load_mean']]),\n",
    "    scaler_agg_freq.transform(aggregated_load[['agg_load_freq']])\n",
    "], axis=1)\n",
    "\n",
    "# Split data into training and test sets (80% training, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features_normalized, train_appliances_normalized, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the training and test data\n",
    "X_train = X_train.reshape(-1, 1, 3)  # Include 3 features: aggregated load, its mean, and its frequency\n",
    "X_test = X_test.reshape(-1, 1, 3)\n",
    "\n",
    "# Prepare features for aggregated load data\n",
    "X_aggregated = aggregated_features_normalized.reshape(-1, 1, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6c021e2-1687-4478-8174-7107ac6c185b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:51:44.273564Z",
     "start_time": "2024-06-09T09:51:15.409144Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jihad\\PycharmProjects\\energyinfo\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,365</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)             │         \u001b[38;5;34m1,365\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,621</span> (6.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,621\u001b[0m (6.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,621</span> (6.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,621\u001b[0m (6.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 848us/step - loss: 0.9464 - val_loss: 0.8197\n",
      "Epoch 2/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 836us/step - loss: 0.8254 - val_loss: 0.7888\n",
      "Epoch 3/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 884us/step - loss: 0.8331 - val_loss: 0.7739\n",
      "Epoch 4/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 870us/step - loss: 0.7856 - val_loss: 0.7646\n",
      "Epoch 5/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 964us/step - loss: 0.8013 - val_loss: 0.7571\n",
      "Epoch 6/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 881us/step - loss: 0.7771 - val_loss: 0.7466\n",
      "Epoch 7/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 940us/step - loss: 0.7833 - val_loss: 0.7420\n",
      "Epoch 8/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.7653 - val_loss: 0.7326\n",
      "Epoch 9/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.7332 - val_loss: 0.7300\n",
      "Epoch 10/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.7747 - val_loss: 0.7213\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 556us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# CNN Model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=1, activation='relu', input_shape=(1, 3)))  # Update input_shape to (1, 3)\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(21, activation='linear'))\n",
    "\n",
    "cnn_model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "cnn_model.summary()\n",
    "\n",
    "# CNN Training\n",
    "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predicting with CNN\n",
    "y_pred_cnn_test = cnn_model.predict(X_test)\n",
    "y_pred_cnn_full = cnn_model.predict(X_aggregated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596846ac-828e-428b-ab2d-7e25af8c3df1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:52:11.361680Z",
     "start_time": "2024-06-09T09:51:44.277113Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jihad\\PycharmProjects\\energyinfo\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,071</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m10,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)             │         \u001b[38;5;34m1,071\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,871</span> (46.37 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,871\u001b[0m (46.37 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,871</span> (46.37 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,871\u001b[0m (46.37 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 827us/step - loss: 0.9020 - val_loss: 0.8144\n",
      "Epoch 2/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 779us/step - loss: 0.8009 - val_loss: 0.7898\n",
      "Epoch 3/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 792us/step - loss: 0.7924 - val_loss: 0.7772\n",
      "Epoch 4/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 895us/step - loss: 0.8595 - val_loss: 0.7666\n",
      "Epoch 5/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 934us/step - loss: 0.7832 - val_loss: 0.7545\n",
      "Epoch 6/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 958us/step - loss: 0.7807 - val_loss: 0.7464\n",
      "Epoch 7/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 847us/step - loss: 0.7619 - val_loss: 0.7369\n",
      "Epoch 8/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.7755 - val_loss: 0.7266\n",
      "Epoch 9/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 913us/step - loss: 0.7739 - val_loss: 0.7204\n",
      "Epoch 10/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 951us/step - loss: 0.7977 - val_loss: 0.7114\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 584us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# LSTM Model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, activation='relu', input_shape=(1, 3)))  # Update input_shape to (1, 3)\n",
    "lstm_model.add(Dense(21))\n",
    "\n",
    "lstm_model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "lstm_model.summary()\n",
    "\n",
    "# LSTM Training\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predicting with LSTM\n",
    "y_pred_lstm_test = lstm_model.predict(X_test)\n",
    "y_pred_lstm_full = lstm_model.predict(X_aggregated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d3c3946feb3a80d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:52:12.554217Z",
     "start_time": "2024-06-09T09:52:11.363703Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train.reshape(-1, 3), y_train)  # Reshape X_train for RandomForest\n",
    "\n",
    "# Predicting with Random Forest\n",
    "y_pred_rf_test = rf_model.predict(X_test.reshape(-1, 3))\n",
    "y_pred_rf_full = rf_model.predict(X_aggregated.reshape(-1, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48b377b8099add1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:52:12.555200Z",
     "start_time": "2024-06-09T09:52:12.555200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       appliance  rmse_cnn  rmse_lstm   rmse_rf\n",
      "0    appliance_1  0.115818   0.115697  0.053510\n",
      "1    appliance_2  0.063365   0.060643  0.017213\n",
      "2    appliance_3  0.120732   0.101668  0.028800\n",
      "3    appliance_4  0.072022   0.071875  0.025376\n",
      "4    appliance_5  0.026112   0.026268  0.016792\n",
      "5    appliance_6  0.142504   0.141431  0.060933\n",
      "6    appliance_7  0.037051   0.037127  0.019167\n",
      "7    appliance_8  0.121368   0.089625  0.030247\n",
      "8    appliance_9  0.032504   0.031759  0.015649\n",
      "9   appliance_10  0.504936   0.502516  0.082220\n",
      "10  appliance_11  0.010030   0.010020  0.010170\n",
      "11  appliance_12  0.215545   0.205802  0.081439\n",
      "12  appliance_13  0.007311   0.007312  0.008297\n",
      "13  appliance_14  0.049319   0.049214  0.028491\n",
      "14  appliance_15  0.091075   0.091025  0.053619\n",
      "15  appliance_16  0.127408   0.127915  0.072600\n",
      "16  appliance_17  0.113832   0.114826  0.049497\n",
      "17  appliance_18  0.155699   0.152781  0.067042\n",
      "18  appliance_19  0.044301   0.044274  0.023113\n",
      "19  appliance_20  0.043366   0.043307  0.016521\n",
      "20  appliance_21  0.049127   0.048944  0.011831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate RMSE as in the provided notebook\n",
    "def calculate_rmse(true_values, pred_values):\n",
    "    true_values_scaled = true_values / true_values.max(axis=0)\n",
    "    pred_values_scaled = pred_values / true_values.max(axis=0)\n",
    "    rmse = np.sqrt(mean_squared_error(true_values_scaled, pred_values_scaled, multioutput='raw_values'))\n",
    "    return rmse\n",
    "\n",
    "# Calculate RMSE for each appliance\n",
    "rmse_cnn = calculate_rmse(y_test, y_pred_cnn_test)\n",
    "rmse_lstm = calculate_rmse(y_test, y_pred_lstm_test)\n",
    "rmse_rf = calculate_rmse(y_test, y_pred_rf_test)\n",
    "\n",
    "# Combine RMSE into a DataFrame for comparison\n",
    "rmse_df = pd.DataFrame({\n",
    "    'appliance': [f'appliance_{i}' for i in range(1, 22)],\n",
    "    'rmse_cnn': rmse_cnn,\n",
    "    'rmse_lstm': rmse_lstm,\n",
    "    'rmse_rf': rmse_rf\n",
    "})\n",
    "\n",
    "print(rmse_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7397cfb-7ccb-4aa3-9136-e752d2e2a867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:52:12.556725Z",
     "start_time": "2024-06-09T09:52:12.556725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       appliance  rmse_cnn  rmse_lstm   rmse_rf best_model\n",
      "0    appliance_1  0.115818   0.115697  0.053510         RF\n",
      "1    appliance_2  0.063365   0.060643  0.017213         RF\n",
      "2    appliance_3  0.120732   0.101668  0.028800         RF\n",
      "3    appliance_4  0.072022   0.071875  0.025376         RF\n",
      "4    appliance_5  0.026112   0.026268  0.016792         RF\n",
      "5    appliance_6  0.142504   0.141431  0.060933         RF\n",
      "6    appliance_7  0.037051   0.037127  0.019167         RF\n",
      "7    appliance_8  0.121368   0.089625  0.030247         RF\n",
      "8    appliance_9  0.032504   0.031759  0.015649         RF\n",
      "9   appliance_10  0.504936   0.502516  0.082220         RF\n",
      "10  appliance_11  0.010030   0.010020  0.010170       LSTM\n",
      "11  appliance_12  0.215545   0.205802  0.081439         RF\n",
      "12  appliance_13  0.007311   0.007312  0.008297        CNN\n",
      "13  appliance_14  0.049319   0.049214  0.028491         RF\n",
      "14  appliance_15  0.091075   0.091025  0.053619         RF\n",
      "15  appliance_16  0.127408   0.127915  0.072600         RF\n",
      "16  appliance_17  0.113832   0.114826  0.049497         RF\n",
      "17  appliance_18  0.155699   0.152781  0.067042         RF\n",
      "18  appliance_19  0.044301   0.044274  0.023113         RF\n",
      "19  appliance_20  0.043366   0.043307  0.016521         RF\n",
      "20  appliance_21  0.049127   0.048944  0.011831         RF\n"
     ]
    }
   ],
   "source": [
    "# Determine the best model for each appliance\n",
    "best_models = rmse_df[['rmse_cnn', 'rmse_lstm', 'rmse_rf']].idxmin(axis=1)\n",
    "best_models = best_models.replace({'rmse_cnn': 'CNN', 'rmse_lstm': 'LSTM', 'rmse_rf': 'RF'})\n",
    "rmse_df['best_model'] = best_models\n",
    "\n",
    "print(rmse_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca862b58-0afb-4c66-be46-01b588c5b025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model RMSE Sum on Test Data: [0.05351014 0.01721342 0.02880005 0.02537591 0.0167919  0.06093277\n",
      " 0.01916724 0.03024693 0.01564889 0.08221996 0.01001972 0.08143932\n",
      " 0.00731135 0.02849126 0.05361942 0.07259979 0.04949721 0.0670421\n",
      " 0.02311253 0.01652113 0.01183085]\n",
      "Hybrid Model RMSE Sum on AggregatedLoad_A: 0.14749399928704257\n"
     ]
    }
   ],
   "source": [
    "# Initialize the hybrid predictions array for test data\n",
    "hybrid_predictions_test = np.zeros_like(y_pred_cnn_test)\n",
    "\n",
    "# Assign the best model's predictions to the hybrid model for test data\n",
    "for i in range(21):\n",
    "    if rmse_df.loc[i, 'best_model'] == 'CNN':\n",
    "        hybrid_predictions_test[:, i] = y_pred_cnn_test[:, i]\n",
    "    elif rmse_df.loc[i, 'best_model'] == 'LSTM':\n",
    "        hybrid_predictions_test[:, i] = y_pred_lstm_test[:, i]\n",
    "    else:\n",
    "        hybrid_predictions_test[:, i] = y_pred_rf_test[:, i]\n",
    "\n",
    "# Calculate and show summed RMSE for the hybrid model on test data\n",
    "rmse_hybrid_test = calculate_rmse(y_test, hybrid_predictions_test)\n",
    "print(\"Hybrid Model RMSE Sum on Test Data:\", rmse_hybrid_test)\n",
    "\n",
    "# Initialize the hybrid predictions array for AggregatedLoad_A\n",
    "hybrid_predictions_full = np.zeros_like(y_pred_cnn_full)\n",
    "\n",
    "# Assign the best model's predictions to the hybrid model for AggregatedLoad_A\n",
    "for i in range(21):\n",
    "    if rmse_df.loc[i, 'best_model'] == 'CNN':\n",
    "        hybrid_predictions_full[:, i] = y_pred_cnn_full[:, i]\n",
    "    elif rmse_df.loc[i, 'best_model'] == 'LSTM':\n",
    "        hybrid_predictions_full[:, i] = y_pred_lstm_full[:, i]\n",
    "    else:\n",
    "        hybrid_predictions_full[:, i] = y_pred_rf_full[:, i]\n",
    "\n",
    "# Save predictions to CSV\n",
    "def save_predictions(predictions, filename):\n",
    "    predictions_scaled = scaler_appliances.inverse_transform(predictions)\n",
    "    template_copy = template.copy()\n",
    "    template_copy.iloc[:, 1:] = predictions_scaled\n",
    "    template_copy.to_csv(filename, index=False)\n",
    "    return predictions_scaled\n",
    "\n",
    "\n",
    "save_predictions(y_pred_cnn_full, 'Predicted_CNN.csv')\n",
    "save_predictions(y_pred_lstm_full, 'Predicted_LSTM.csv')\n",
    "save_predictions(y_pred_rf_full, 'Predicted_RF.csv')\n",
    "hybrid_predictions_full=save_predictions(hybrid_predictions_full, 'Predicted_Hybrid.csv')\n",
    "\n",
    "\n",
    "# Load ground truth data for AggregatedLoad_A\n",
    "true_A = pd.read_csv(\"TestData_A.csv\", index_col=0)\n",
    "true_A = true_A.iloc[:, 1:]  # Ignore aggregate load column\n",
    "true_A_values_scaled = true_A.values / true_A.max(axis=0).values\n",
    "\n",
    "# Calculate and show summed RMSE for the hybrid model on AggregatedLoad_A\n",
    "pred_A_values_scaled = hybrid_predictions_full / true_A.max(axis=0).values\n",
    "rmse_sum_hybrid = np.sum(mean_squared_error(true_A_values_scaled, pred_A_values_scaled, multioutput=\"raw_values\"))\n",
    "print(\"Hybrid Model RMSE Sum on AggregatedLoad_A:\", rmse_sum_hybrid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
